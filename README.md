# News Article Natural Language Dataset Project

## Structure of the Repo

### Exploratory Data Analysis
Within the [News Data Set EDA notebook](https://github.com/cpuglis1/ProbStoch-I-Project/blob/main/News%20Data%20Set%20EDA.ipynb), the news article headline and descriptions are cleaned, processed, and lemmatized following NLP standards. The data is further explored with sentiment analysis, term-frequency word clouds, topic distributions, and TF-IDF category topic analysis. 

### Latent Dirichlet Allocation (LDA) and Dynamic Topic Modeling (DTM) Hidden Topic Exploration
Within the [LDA DTM notebook](https://github.com/cpuglis1/ProbStoch-I-Project/blob/main/LDA%20DTM%20ProbStoch%20Code.ipynb), LDA and DTM are performed on article headlines to identify hidden topics. Model results are returned and quantified using perplexity and coherence. For a complete write-up analysis, justification for model choices, a dive into the probabilistic theory, and more robust results analysis, please refer to the write up [Bayesian Topic Modeling of News Articles](https://github.com/cpuglis1/ProbStoch-I-Project/blob/main/Bayesian%20Topic%20Modeling%20of%20News%20Articles.pdf).

### News Article Classifcation
Within the [Linear SVC](https://github.com/cpuglis1/ProbStoch-I-Project/blob/main/linear_svc_news_headline_classifier.ipynb), [Logisitic Regression](https://github.com/cpuglis1/ProbStoch-I-Project/blob/main/logistic_regression_news_headline_classifier.ipynb), and [Shallow Neural Net classifier](https://github.com/cpuglis1/ProbStoch-I-Project/blob/main/shallow_neural_net_news_headline_classifier.ipynb) notebooks, classification is performed on the news articles. The results ended up beyond the scope of the write up and were not included in said paper.

